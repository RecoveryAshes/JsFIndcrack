package core

import (
	"fmt"
	"time"

	"github.com/RecoveryAshes/JsFIndcrack/internal/models"
	"github.com/RecoveryAshes/JsFIndcrack/internal/utils"
)

// BatchCrawler æ‰¹é‡çˆ¬å–å™¨
type BatchCrawler struct {
	config         models.CrawlConfig
	outputDir      string
	mode           string
	batchDelay     time.Duration
	continueOnErr  bool
	headerProvider models.HeaderProvider
}

// BatchResult æ‰¹é‡çˆ¬å–ç»“æœ
type BatchResult struct {
	URL         string
	Success     bool
	Error       error
	Stats       models.TaskStats
	ProcessedAt time.Time
	Duration    float64
}

// BatchSummary æ‰¹é‡çˆ¬å–æ‘˜è¦
type BatchSummary struct {
	TotalURLs     int
	SuccessCount  int
	FailCount     int
	TotalFiles    int
	TotalSize     int64
	TotalDuration float64
	Results       []BatchResult
}

// NewBatchCrawler åˆ›å»ºæ‰¹é‡çˆ¬å–å™¨
func NewBatchCrawler(config models.CrawlConfig, outputDir string, mode string, batchDelay int, continueOnErr bool, headerProvider models.HeaderProvider) *BatchCrawler {
	return &BatchCrawler{
		config:         config,
		outputDir:      outputDir,
		mode:           mode,
		batchDelay:     time.Duration(batchDelay) * time.Second,
		continueOnErr:  continueOnErr,
		headerProvider: headerProvider,
	}
}

// CrawlBatch æ‰¹é‡çˆ¬å–URLåˆ—è¡¨
func (bc *BatchCrawler) CrawlBatch(urls []string) (*BatchSummary, error) {
	utils.Infof("ğŸš€ å¼€å§‹æ‰¹é‡çˆ¬å–: %dä¸ªURL", len(urls))

	summary := &BatchSummary{
		TotalURLs: len(urls),
		Results:   make([]BatchResult, 0, len(urls)),
	}

	startTime := time.Now()

	for i, targetURL := range urls {
		utils.Infof("\n==================== [%d/%d] ====================", i+1, len(urls))
		utils.Infof("ğŸ¯ ç›®æ ‡URL: %s", targetURL)

		// æ‰§è¡Œå•ä¸ªURLçˆ¬å–
		result := bc.crawlSingleURL(targetURL, i+1)
		summary.Results = append(summary.Results, result)

		// æ›´æ–°ç»Ÿè®¡
		if result.Success {
			summary.SuccessCount++
			summary.TotalFiles += result.Stats.TotalFiles
			summary.TotalSize += result.Stats.TotalSize

			// ç›®æ ‡å®Œæˆåçš„éš”ç¦»æ—¥å¿—
			utils.Infof("âœ… ç›®æ ‡ %d/%d å®Œæˆ,ç‹¬ç«‹ç»Ÿè®¡:", i+1, len(urls))
			utils.Infof("   - è®¿é—®URLæ•°: %d", result.Stats.VisitedURLs)
			utils.Infof("   - ä¸‹è½½æ–‡ä»¶æ•°: %d", result.Stats.TotalFiles)
			utils.Infof("   - æ–‡ä»¶å¤§å°: %.2f MB", float64(result.Stats.TotalSize)/(1024*1024))
			utils.Infof("   - è€—æ—¶: %.2fç§’", result.Duration)
			utils.Debugf("ç›®æ ‡ %d é˜Ÿåˆ—å·²æ¸…ç©º,æ ‡ç­¾é¡µæ± å·²é‡ç½®,å‡†å¤‡å¤„ç†ä¸‹ä¸€ä¸ªç›®æ ‡", i+1)
		} else {
			summary.FailCount++
			utils.Errorf("âŒ ç›®æ ‡ %d/%d çˆ¬å–å¤±è´¥: %v", i+1, len(urls), result.Error)

			// å¦‚æœä¸ç»§ç»­å¤„ç†é”™è¯¯,åˆ™åœæ­¢
			if !bc.continueOnErr {
				utils.Warn("æ‰¹é‡çˆ¬å–ä¸­æ­¢ (--continue-on-error=false)")
				break
			}
		}

		// æ‰¹é‡å»¶è¿Ÿ(æœ€åä¸€ä¸ªURLä¸éœ€è¦å»¶è¿Ÿ)
		if i < len(urls)-1 && bc.batchDelay > 0 {
			utils.Debugf("ç­‰å¾… %.0f ç§’åå¤„ç†ä¸‹ä¸€ä¸ªURL...", bc.batchDelay.Seconds())
			time.Sleep(bc.batchDelay)
		}
	}

	summary.TotalDuration = time.Since(startTime).Seconds()

	// æ˜¾ç¤ºæ‰¹é‡çˆ¬å–æ‘˜è¦
	bc.printSummary(summary)

	return summary, nil
}

// crawlSingleURL çˆ¬å–å•ä¸ªURL
// å‚æ•°:
//   - targetURL: ç›®æ ‡URL
//   - targetIndex: ç›®æ ‡ç´¢å¼•(ç”¨äºæ—¥å¿—æ˜¾ç¤º)
func (bc *BatchCrawler) crawlSingleURL(targetURL string, targetIndex int) BatchResult {
	result := BatchResult{
		URL:         targetURL,
		ProcessedAt: time.Now(),
	}

	startTime := time.Now()

	utils.Debugf("å¼€å§‹çˆ¬å–ç›®æ ‡ %d: %s", targetIndex, targetURL)

	// åˆ›å»ºçˆ¬å–å™¨
	crawler, err := NewCrawler(targetURL, bc.config, bc.outputDir, bc.mode, bc.headerProvider)
	if err != nil {
		result.Success = false
		result.Error = fmt.Errorf("åˆ›å»ºçˆ¬å–å™¨å¤±è´¥: %w", err)
		result.Duration = time.Since(startTime).Seconds()
		return result
	}

	// æ‰§è¡Œçˆ¬å–
	if err := crawler.Crawl(); err != nil {
		result.Success = false
		result.Error = fmt.Errorf("çˆ¬å–å¤±è´¥: %w", err)
		result.Duration = time.Since(startTime).Seconds()
		return result
	}

	// æˆåŠŸ
	result.Success = true
	result.Stats = crawler.GetStats()
	result.Duration = time.Since(startTime).Seconds()

	return result
}

// printSummary æ‰“å°æ‰¹é‡çˆ¬å–æ‘˜è¦
func (bc *BatchCrawler) printSummary(summary *BatchSummary) {
	utils.Info("\n==================================================")
	utils.Info("ğŸ“Š æ‰¹é‡çˆ¬å–æ‘˜è¦")
	utils.Info("==================================================")
	utils.Infof("æ€»URLæ•°: %d", summary.TotalURLs)
	utils.Infof("âœ… æˆåŠŸ: %d", summary.SuccessCount)
	utils.Infof("âŒ å¤±è´¥: %d", summary.FailCount)
	utils.Infof("ğŸ“¦ æ€»æ–‡ä»¶æ•°: %d", summary.TotalFiles)
	utils.Infof("ğŸ“¦ æ€»å¤§å°: %.2f MB", float64(summary.TotalSize)/(1024*1024))
	utils.Infof("â±ï¸  æ€»è€—æ—¶: %.2fç§’", summary.TotalDuration)
	utils.Info("==================================================")

	// æ˜¾ç¤ºå¤±è´¥çš„URL
	if summary.FailCount > 0 {
		utils.Warn("\nå¤±è´¥çš„URL:")
		for _, result := range summary.Results {
			if !result.Success {
				utils.Warnf("  - %s: %v", result.URL, result.Error)
			}
		}
	}
}

package crawlers

import (
	"context"
	"crypto/sha256"
	"fmt"
	"net/url"
	"os"
	"path/filepath"
	"runtime"
	"strings"
	"sync"
	"time"

	"github.com/RecoveryAshes/JsFIndcrack/internal/models"
	"github.com/RecoveryAshes/JsFIndcrack/internal/utils"
	"github.com/go-rod/rod"
	"github.com/go-rod/rod/lib/launcher"
	"github.com/go-rod/rod/lib/proto"
	"github.com/google/uuid"
)

// DynamicCrawler åŠ¨æ€çˆ¬å–å™¨(ä½¿ç”¨Rod)
type DynamicCrawler struct {
	browser   *rod.Browser
	config    models.CrawlConfig
	outputDir string
	domain    string

	// HTTPå¤´éƒ¨æä¾›è€…
	headerProvider models.HeaderProvider

	// æ–‡ä»¶å­˜å‚¨
	jsFiles  map[string]*models.JSFile  // URL -> JSFile
	mapFiles map[string]*models.MapFile // URL -> MapFile
	mu       sync.RWMutex               // ä¿æŠ¤maps

	// å…¨å±€æ–‡ä»¶å“ˆå¸Œè¡¨(ç”¨äºè·¨çˆ¬å–å™¨å»é‡)
	globalFileHashes map[string]string // hash -> URL (shared with static crawler)
	globalMu         *sync.RWMutex     // ä¿æŠ¤globalFileHashesçš„äº’æ–¥é”

	// ç»Ÿè®¡
	visitedURLs []string
	stats       models.TaskStats

	// é¡µé¢æ± ç”¨äºå¹¶å‘
	pagePool chan *rod.Page
	ctx      context.Context
	cancel   context.CancelFunc
}

// NewDynamicCrawler åˆ›å»ºåŠ¨æ€çˆ¬å–å™¨
func NewDynamicCrawler(config models.CrawlConfig, outputDir string, domain string, globalFileHashes map[string]string, globalMu *sync.RWMutex, headerProvider models.HeaderProvider) *DynamicCrawler {
	ctx, cancel := context.WithCancel(context.Background())

	// åŠ¨æ€è®¡ç®—æœ€ä¼˜æ ‡ç­¾é¡µæ•°
	// ç­–ç•¥: åŸºäºCPUæ ¸å¿ƒæ•°å’Œå†…å­˜,é¿å…è¿‡åº¦æ¶ˆè€—
	optimalTabs := calculateOptimalTabs(config.PlaywrightTabs)

	utils.Debugf("åŠ¨æ€çˆ¬å–å™¨æ ‡ç­¾é¡µæ± ä¼˜åŒ–: é…ç½®=%d, CPUæ ¸å¿ƒ=%d, æœ€ä¼˜æ ‡ç­¾é¡µ=%d",
		config.PlaywrightTabs, runtime.NumCPU(), optimalTabs)

	dc := &DynamicCrawler{
		config:           config,
		outputDir:        outputDir,
		domain:           domain,
		headerProvider:   headerProvider,
		jsFiles:          make(map[string]*models.JSFile),
		mapFiles:         make(map[string]*models.MapFile),
		globalFileHashes: globalFileHashes,
		globalMu:         globalMu,
		visitedURLs:      make([]string, 0),
		stats:            models.TaskStats{},
		pagePool:         make(chan *rod.Page, optimalTabs), // ä½¿ç”¨ä¼˜åŒ–åçš„æ ‡ç­¾é¡µæ•°
		ctx:              ctx,
		cancel:           cancel,
	}

	// æ›´æ–°configä¸­çš„PlaywrightTabsä¸ºä¼˜åŒ–åçš„å€¼
	dc.config.PlaywrightTabs = optimalTabs

	return dc
}

// Crawl å¼€å§‹åŠ¨æ€çˆ¬å–
func (dc *DynamicCrawler) Crawl(targetURL string) error {
	startTime := time.Now()

	utils.Infof("ğŸŒ åŠ¨æ€çˆ¬å–æ¨¡å¼å¯åŠ¨")
	utils.Infof("ç›®æ ‡URL: %s", targetURL)
	utils.Infof("ç­‰å¾…æ—¶é—´: %dç§’", dc.config.WaitTime)
	utils.Infof("æ ‡ç­¾é¡µæ•°: %d", dc.config.PlaywrightTabs)

	// å¯åŠ¨æµè§ˆå™¨
	if err := dc.launchBrowser(); err != nil {
		return fmt.Errorf("å¯åŠ¨æµè§ˆå™¨å¤±è´¥: %w", err)
	}
	defer dc.closeBrowser()

	// åˆå§‹åŒ–é¡µé¢æ± 
	if err := dc.initPagePool(); err != nil {
		return fmt.Errorf("åˆå§‹åŒ–é¡µé¢æ± å¤±è´¥: %w", err)
	}

	// çˆ¬å–ç›®æ ‡URL
	if err := dc.crawlPage(targetURL, 0); err != nil {
		utils.Errorf("çˆ¬å–å¤±è´¥: %v", err)
		return err
	}

	duration := time.Since(startTime)
	dc.stats.Duration = duration.Seconds()

	utils.Infof("âœ… åŠ¨æ€çˆ¬å–å®Œæˆ")
	utils.Infof("è®¿é—®URLæ•°: %d", dc.stats.VisitedURLs)
	utils.Infof("ä¸‹è½½æ–‡ä»¶æ•°: %d", dc.stats.DynamicFiles)
	utils.Infof("å¤±è´¥æ–‡ä»¶æ•°: %d", dc.stats.FailedFiles)
	utils.Infof("æ€»è€—æ—¶: %.2fç§’", dc.stats.Duration)

	return nil
}

// launchBrowser å¯åŠ¨æµè§ˆå™¨
func (dc *DynamicCrawler) launchBrowser() error {
	// é…ç½®launcher
	l := launcher.New()

	if dc.config.Headless {
		l = l.Headless(true)
	} else {
		l = l.Headless(false)
	}

	// å¯åŠ¨æµè§ˆå™¨
	controlURL, err := l.Launch()
	if err != nil {
		return fmt.Errorf("å¯åŠ¨æµè§ˆå™¨å¤±è´¥: %w", err)
	}

	// è¿æ¥åˆ°æµè§ˆå™¨
	dc.browser = rod.New().ControlURL(controlURL)
	if err := dc.browser.Connect(); err != nil {
		return fmt.Errorf("è¿æ¥æµè§ˆå™¨å¤±è´¥: %w", err)
	}

	utils.Debugf("æµè§ˆå™¨å·²å¯åŠ¨: %s", controlURL)
	return nil
}

// closeBrowser å…³é—­æµè§ˆå™¨
func (dc *DynamicCrawler) closeBrowser() {
	if dc.browser != nil {
		dc.cancel()
		close(dc.pagePool)
		dc.browser.MustClose()
		utils.Debugf("æµè§ˆå™¨å·²å…³é—­")
	}
}

// initPagePool åˆå§‹åŒ–é¡µé¢æ± 
func (dc *DynamicCrawler) initPagePool() error {
	for i := 0; i < dc.config.PlaywrightTabs; i++ {
		page, err := dc.browser.Page(proto.TargetCreateTarget{})
		if err != nil {
			return fmt.Errorf("åˆ›å»ºé¡µé¢å¤±è´¥: %w", err)
		}

		// è®¾ç½®ç½‘ç»œæ‹¦æˆª
		if err := dc.setupNetworkIntercept(page); err != nil {
			return fmt.Errorf("è®¾ç½®ç½‘ç»œæ‹¦æˆªå¤±è´¥: %w", err)
		}

		dc.pagePool <- page
		utils.Debugf("åˆ›å»ºé¡µé¢æ± æ ‡ç­¾é¡µ %d/%d", i+1, dc.config.PlaywrightTabs)
	}

	return nil
}

// setupNetworkIntercept è®¾ç½®ç½‘ç»œè¯·æ±‚æ‹¦æˆª
func (dc *DynamicCrawler) setupNetworkIntercept(page *rod.Page) error {
	// å¯ç”¨ç½‘ç»œåŸŸ
	router := page.HijackRequests()

	router.MustAdd("*", func(ctx *rod.Hijack) {
		// åº”ç”¨è‡ªå®šä¹‰HTTPå¤´éƒ¨
		if dc.headerProvider != nil {
			headers, err := dc.headerProvider.GetHeaders()
			if err != nil {
				utils.Warnf("è·å–HTTPå¤´éƒ¨å¤±è´¥: %v", err)
			} else {
				for name, values := range headers {
					if len(values) > 0 {
						ctx.Request.Req().Header.Set(name, values[0])
					}
				}
			}
		}

		// è·å–è¯·æ±‚URL
		requestURL := ctx.Request.URL().String()

		// æ£€æŸ¥æ˜¯å¦ä¸ºJavaScriptæ–‡ä»¶
		if dc.isJavaScriptURL(requestURL) {
			utils.Debugf("æ‹¦æˆªJSè¯·æ±‚: %s", requestURL)
		}

		// ç»§ç»­è¯·æ±‚
		ctx.MustLoadResponse()

		// å¦‚æœæ˜¯JavaScriptæ–‡ä»¶,ä¿å­˜å“åº”
		if dc.isJavaScriptURL(requestURL) {
			if ctx.Response != nil {
				body := ctx.Response.Body()
				// è·å–Content-Type
				contentType := "application/javascript"
				dc.downloadJSFile(requestURL, []byte(body), contentType)
			}
		}
	})

	go router.Run()

	return nil
}

// crawlPage çˆ¬å–å•ä¸ªé¡µé¢
func (dc *DynamicCrawler) crawlPage(pageURL string, depth int) error {
	// æ£€æŸ¥æ·±åº¦é™åˆ¶
	if depth > dc.config.Depth {
		return nil
	}

	// è®°å½•è®¿é—®
	dc.mu.Lock()
	dc.visitedURLs = append(dc.visitedURLs, pageURL)
	dc.stats.VisitedURLs++
	dc.mu.Unlock()

	utils.Debugf("è®¿é—®é¡µé¢: %s (æ·±åº¦: %d)", pageURL, depth)

	// ä»é¡µé¢æ± è·å–é¡µé¢
	page := <-dc.pagePool
	defer func() {
		// é¡µé¢å¤ç”¨å‰æ¸…ç†çŠ¶æ€
		// æ¸…ç†ç¼“å­˜ã€Cookieã€å­˜å‚¨,é¿å…çŠ¶æ€æ±¡æŸ“
		cleanupPage(page)
		dc.pagePool <- page // å½’è¿˜é¡µé¢åˆ°æ± 
	}()

	// å¯¼èˆªåˆ°ç›®æ ‡URL
	if err := page.Navigate(pageURL); err != nil {
		utils.Errorf("å¯¼èˆªå¤±è´¥ [%s]: %v", pageURL, err)
		dc.stats.FailedFiles++
		return err
	}

	// ç­‰å¾…é¡µé¢åŠ è½½
	if err := page.WaitLoad(); err != nil {
		utils.Errorf("ç­‰å¾…é¡µé¢åŠ è½½å¤±è´¥ [%s]: %v", pageURL, err)
		return err
	}

	// é¢å¤–ç­‰å¾…æ—¶é—´(ç­‰å¾…åŠ¨æ€JSåŠ è½½)
	time.Sleep(time.Duration(dc.config.WaitTime) * time.Second)

	utils.Debugf("é¡µé¢åŠ è½½å®Œæˆ: %s", pageURL)

	return nil
}

// downloadJSFile ä¸‹è½½å¹¶ä¿å­˜JavaScriptæ–‡ä»¶
func (dc *DynamicCrawler) downloadJSFile(fileURL string, content []byte, contentType string) error {
	dc.mu.Lock()
	defer dc.mu.Unlock()

	// æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
	if _, exists := dc.jsFiles[fileURL]; exists {
		utils.Debugf("æ–‡ä»¶å·²å­˜åœ¨,è·³è¿‡: %s", fileURL)
		return nil
	}

	// è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
	hash := fmt.Sprintf("%x", sha256.Sum256(content))

	// å…ˆæ£€æŸ¥å…¨å±€å“ˆå¸Œè¡¨(è·¨çˆ¬å–å™¨å»é‡)
	if dc.globalFileHashes != nil && dc.globalMu != nil {
		dc.globalMu.RLock()
		if existingURL, exists := dc.globalFileHashes[hash]; exists {
			dc.globalMu.RUnlock()
			utils.Debugf("å‘ç°å…¨å±€é‡å¤æ–‡ä»¶(å“ˆå¸Œç›¸åŒ): %s (ä¸ %s ç›¸åŒ)", fileURL, existingURL)

			// åˆ›å»ºä¸€ä¸ªæ ‡è®°ä¸ºé‡å¤çš„JSFileå¯¹è±¡,ä½†ä¸ä¿å­˜åˆ°ç£ç›˜
			jsFile := &models.JSFile{
				ID:           uuid.New().String(),
				URL:          fileURL,
				FilePath:     "", // ä¸ä¿å­˜æ–‡ä»¶
				Hash:         hash,
				Size:         int64(len(content)),
				Extension:    filepath.Ext(fileURL),
				ContentType:  contentType,
				SourceURL:    fileURL,
				CrawlMode:    models.ModeDynamic,
				Depth:        0,
				IsObfuscated: false,
				IsDuplicate:  true,
				DownloadedAt: time.Now(),
				HasMapFile:   false,
			}
			dc.jsFiles[fileURL] = jsFile
			return nil
		}
		dc.globalMu.RUnlock()
	}

	// æ£€æŸ¥æœ¬åœ°å“ˆå¸Œå»é‡
	for _, existingFile := range dc.jsFiles {
		if existingFile.Hash == hash {
			utils.Debugf("å‘ç°é‡å¤æ–‡ä»¶(å“ˆå¸Œç›¸åŒ): %s", fileURL)
			dc.jsFiles[fileURL] = existingFile
			existingFile.IsDuplicate = true
			return nil
		}
	}

	// ç”Ÿæˆæ–‡ä»¶è·¯å¾„
	filePath, err := dc.generateFilePath(fileURL, "encode/js")
	if err != nil {
		return fmt.Errorf("ç”Ÿæˆæ–‡ä»¶è·¯å¾„å¤±è´¥: %w", err)
	}

	// ç¡®ä¿ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(filepath.Dir(filePath), 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºç›®å½•å¤±è´¥: %w", err)
	}

	// å†™å…¥æ–‡ä»¶
	if err := os.WriteFile(filePath, content, 0644); err != nil {
		return fmt.Errorf("å†™å…¥æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// åˆ›å»ºJSFileå¯¹è±¡
	jsFile := &models.JSFile{
		ID:           uuid.New().String(),
		URL:          fileURL,
		FilePath:     filePath,
		Hash:         hash,
		Size:         int64(len(content)),
		Extension:    filepath.Ext(fileURL),
		ContentType:  contentType,
		SourceURL:    fileURL,
		CrawlMode:    models.ModeDynamic,
		Depth:        0, // TODO: è·Ÿè¸ªå®é™…æ·±åº¦
		IsObfuscated: false,
		DownloadedAt: time.Now(),
		HasMapFile:   false,
	}

	dc.jsFiles[fileURL] = jsFile
	dc.stats.DynamicFiles++
	dc.stats.TotalFiles++
	dc.stats.TotalSize += int64(len(content))

	// æ·»åŠ åˆ°å…¨å±€å“ˆå¸Œè¡¨
	if dc.globalFileHashes != nil && dc.globalMu != nil {
		dc.globalMu.Lock()
		dc.globalFileHashes[hash] = fileURL
		dc.globalMu.Unlock()
	}

	utils.Infof("ğŸ“¥ ä¸‹è½½æˆåŠŸ: %s (%d bytes)", filepath.Base(filePath), len(content))

	// æ£€æŸ¥æ˜¯å¦æœ‰Source Map
	dc.checkAndDownloadSourceMap(fileURL, content)

	return nil
}

// checkAndDownloadSourceMap æ£€æŸ¥å¹¶ä¸‹è½½Source Mapæ–‡ä»¶
func (dc *DynamicCrawler) checkAndDownloadSourceMap(jsURL string, jsContent []byte) {
	// åœ¨æ–‡ä»¶å†…å®¹ä¸­æŸ¥æ‰¾sourceMappingURLæ³¨é‡Š
	content := string(jsContent)

	// æŸ¥æ‰¾ //# sourceMappingURL=xxx.map
	if idx := strings.Index(content, "sourceMappingURL="); idx != -1 {
		start := idx + len("sourceMappingURL=")
		end := strings.IndexAny(content[start:], "\n\r ")
		if end == -1 {
			end = len(content) - start
		}

		mapURL := strings.TrimSpace(content[start : start+end])

		// æ„é€ å®Œæ•´URL
		baseURL, _ := url.Parse(jsURL)
		fullMapURL, err := baseURL.Parse(mapURL)
		if err == nil {
			utils.Infof("ğŸ—ºï¸  å‘ç°Source Map: %s", fullMapURL.String())
			// TODO: ä¸‹è½½Source Mapæ–‡ä»¶
			dc.stats.MapFiles++
		}
	}
}

// isJavaScriptURL åˆ¤æ–­æ˜¯å¦ä¸ºJavaScriptæ–‡ä»¶URL
func (dc *DynamicCrawler) isJavaScriptURL(urlStr string) bool {
	urlStr = strings.ToLower(urlStr)

	// æ£€æŸ¥æ‰©å±•å
	for _, ext := range models.JSFileExtensions {
		if strings.HasSuffix(urlStr, ext) {
			return true
		}
	}

	// æ£€æŸ¥å¸¸è§JSæ¨¡å¼
	if strings.Contains(urlStr, ".js?") ||
		strings.Contains(urlStr, ".mjs?") ||
		strings.Contains(urlStr, ".jsx?") {
		return true
	}

	// æ£€æŸ¥Content-Type (å¦‚æœå¯ç”¨)
	return false
}

// generateFilePath ç”Ÿæˆæœ¬åœ°æ–‡ä»¶è·¯å¾„
func (dc *DynamicCrawler) generateFilePath(fileURL string, subdir string) (string, error) {
	parsed, err := url.Parse(fileURL)
	if err != nil {
		return "", err
	}

	// ä½¿ç”¨URLè·¯å¾„ä½œä¸ºæ–‡ä»¶å
	filename := filepath.Base(parsed.Path)
	if filename == "" || filename == "." {
		filename = "index.js"
	}

	// æ„é€ å®Œæ•´è·¯å¾„: output/domain/encode/js/filename
	fullPath := filepath.Join(dc.outputDir, dc.domain, subdir, filename)

	// å¦‚æœæ–‡ä»¶å·²å­˜åœ¨,æ·»åŠ ç¼–å·
	if _, err := os.Stat(fullPath); err == nil {
		ext := filepath.Ext(filename)
		base := strings.TrimSuffix(filename, ext)
		for i := 1; ; i++ {
			newPath := filepath.Join(dc.outputDir, dc.domain, subdir, fmt.Sprintf("%s_%d%s", base, i, ext))
			if _, err := os.Stat(newPath); os.IsNotExist(err) {
				fullPath = newPath
				break
			}
		}
	}

	return fullPath, nil
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (dc *DynamicCrawler) GetStats() models.TaskStats {
	dc.mu.RLock()
	defer dc.mu.RUnlock()
	return dc.stats
}

// GetJSFiles è·å–æ‰€æœ‰ä¸‹è½½çš„JSæ–‡ä»¶
func (dc *DynamicCrawler) GetJSFiles() []*models.JSFile {
	dc.mu.RLock()
	defer dc.mu.RUnlock()

	files := make([]*models.JSFile, 0, len(dc.jsFiles))
	for _, f := range dc.jsFiles {
		files = append(files, f)
	}
	return files
}

// calculateOptimalTabs åŠ¨æ€è®¡ç®—æœ€ä¼˜æ ‡ç­¾é¡µæ•°
// æ ¹æ®CPUæ ¸å¿ƒæ•°å’Œå†…å­˜æ™ºèƒ½è°ƒæ•´æ ‡ç­¾é¡µæ•°
// æµè§ˆå™¨æ ‡ç­¾é¡µæ¯”æ™®é€šçº¿ç¨‹æ›´æ¶ˆè€—èµ„æº,éœ€è¦ä¿å®ˆä¼°è®¡
func calculateOptimalTabs(configTabs int) int {
	numCPU := runtime.NumCPU()

	// åŸºç¡€å€¼
	baseTabs := configTabs
	if baseTabs < 1 {
		baseTabs = 4 // é»˜è®¤4ä¸ªæ ‡ç­¾é¡µ
	}

	// æµè§ˆå™¨æ ‡ç­¾é¡µæ¶ˆè€—å¤§,æœ€å¤šä¸è¶…è¿‡ min(CPUæ ¸å¿ƒæ•°, é…ç½®å€¼*2)
	maxTabs := numCPU
	if baseTabs*2 < maxTabs {
		maxTabs = baseTabs * 2
	}

	// ä¿å®ˆç­–ç•¥,é¿å…æµè§ˆå™¨å¡é¡¿
	switch {
	case numCPU <= 2:
		// ä½æ ¸å¿ƒ: æœ€å¤š2ä¸ªæ ‡ç­¾é¡µ
		if maxTabs > 2 {
			return 2
		}
		return maxTabs
	case numCPU <= 4:
		// ä¸­ç­‰: æœ€å¤š4ä¸ªæ ‡ç­¾é¡µ
		if maxTabs > 4 {
			return 4
		}
		return maxTabs
	case numCPU <= 8:
		// å¤šæ ¸: æœ€å¤š6ä¸ªæ ‡ç­¾é¡µ
		if maxTabs > 6 {
			return 6
		}
		return maxTabs
	default:
		// é«˜æ ¸å¿ƒ: æœ€å¤š8ä¸ªæ ‡ç­¾é¡µ (é¿å…å†…å­˜æº¢å‡º)
		if maxTabs > 8 {
			return 8
		}
		return maxTabs
	}
}

// cleanupPage æ¸…ç†é¡µé¢çŠ¶æ€ä»¥ä¾›å¤ç”¨
// æ¸…é™¤ç¼“å­˜ã€Cookieã€LocalStorageç­‰,é¿å…é¡µé¢é—´çŠ¶æ€æ±¡æŸ“
func cleanupPage(page *rod.Page) {
	// å¿½ç•¥é”™è¯¯,å› ä¸ºæ¸…ç†å¤±è´¥ä¸åº”å½±å“åç»­çˆ¬å–
	_, _ = page.Eval(`() => {
		// æ¸…ç†LocalStorage
		try { localStorage.clear(); } catch(e) {}
		// æ¸…ç†SessionStorage
		try { sessionStorage.clear(); } catch(e) {}
		// æ¸…ç†IndexedDB (å¼‚æ­¥,å°½åŠ›è€Œä¸º)
		try {
			if (window.indexedDB && window.indexedDB.databases) {
				window.indexedDB.databases().then(dbs => {
					dbs.forEach(db => {
						if (db.name) {
							window.indexedDB.deleteDatabase(db.name);
						}
					});
				});
			}
		} catch(e) {}
	}`)
}
